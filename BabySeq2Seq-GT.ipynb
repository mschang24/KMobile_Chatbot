// cells
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size=256 # 256개 아스키 코드\n",
    "target_vocab_size=vocab_size # seq2seq는 매 시간 단위마다 256개 클래스(ASCII 코드) 중 하나를 선택 (분류)\n",
    "learning_rate=0.1\n",
    "buckets=[(12, 12)] # seq2seq는 배치 학습을 하기 때문에, 입력을 길이별로 묶음 (bucket). 이번 시간에는 한 개의 bucket만 다루기로함.\n",
    "PAD=[0] # 만약 입력/타겟 문장이 bucket 크기보다 작을 경우, 0을 패딩해줌.\n",
    "GO=[1] # 디코더 RNN에 GO 라는 기호를 가장 첫 입력으로 넣어줌.\n",
    "batch_size=1\n",
    "input_string = \"Hi Tacademy\"\n",
    "input_string1 = \"Hi Korea\"\n",
    "target_string = \"How are you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_PAD_size = buckets[0][0] - len(input_string) # 입력 문장에 PAD를 얼만큼 해줄지 결정\n",
    "input_PAD_size1 = buckets[0][0] - len(input_string1) # 입력 문장에 PAD를 얼만큼 해줄지 결정\n",
    "target_PAD_size = buckets[0][0] - len(target_string) - 1 # 타켓 문장에 PAD를 얼만큼 해줄지 결정\n",
    "input_data    = (map(ord, input_string) + PAD * input_PAD_size) * batch_size # 입력 문장을 아스키 코드들의 리스트로 변경\n",
    "input_data1    = (map(ord, input_string1) + PAD * input_PAD_size1) * batch_size\n",
    "target_data   = (GO + map(ord, target_string) + PAD * target_PAD_size) * batch_size # 타겟 문장을 아스키 코드들의 리스트로 변경\n",
    "target_weights= ([1.0]*12 + [0.0]*0) * batch_size  # 타겟 문장에서 PAD를 제외한 실제 유효한 (loss를 계산해야하는) 낱글자의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BabySeq2Seq(object):\n",
    "        def __init__(self, source_vocab_size, target_vocab_size, buckets, size, num_layers, batch_size):\n",
    "                self.buckets = buckets\n",
    "                self.batch_size = batch_size\n",
    "                self.source_vocab_size = source_vocab_size\n",
    "                self.target_vocab_size = target_vocab_size\n",
    "\n",
    "                cell = single_cell = tf.contrib.rnn.GRUCell(size)\n",
    "                if num_layers > 1:\n",
    "                 cell = tf.contrib.rnn.MultiRNNCell([single_cell] * num_layers)\n",
    "\n",
    "                # The seq2seq function\n",
    "                # encoder_inputs: 입력 문장의 아스키 코드들로 이뤄진 리스트\n",
    "                # decoder_inputs: 타겟 문장의 아스키 코드들로 이뤄진 리스트\n",
    "                # cell: seq2seq에 사용할 RNN cell\n",
    "                # num_encoder_symbols, num_decoder_symbols: 입력 문장, 타겟 문장의 심볼 개수\n",
    "                # embedding_size: 각 아스키 코드를 임베딩 시킬 크기\n",
    "                # feed_previous: 추론 여부 (학습인 경우 false / 추론인 경우 true)\n",
    "                def seq2seq_f(encoder_inputs, decoder_inputs, do_decode):\n",
    "                        return tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(\n",
    "                                        encoder_inputs, decoder_inputs, cell,\n",
    "                                        num_encoder_symbols=source_vocab_size,\n",
    "                                        num_decoder_symbols=target_vocab_size,\n",
    "                                        embedding_size=size,\n",
    "                                        feed_previous=do_decode)\n",
    "                    \n",
    "                # computational graph 생성\n",
    "                self.encoder_inputs = []\n",
    "                self.decoder_inputs = []\n",
    "                self.target_weights = []\n",
    "                for i in xrange(buckets[-1][0]):        \n",
    "                        self.encoder_inputs.append(tf.placeholder(tf.int32, shape=[None], name=\"encoder{0}\".format(i)))\n",
    "                # 디코더 입력 노드로 bucket 크기 + 한 개를 생성. (한 개 추가 생성은 타겟 심볼은 디코더 입력을 한 칸 shift 한 것과 같고, \n",
    "                # bucket 크기만큼의 target 노드가 생성되어야하기 때문)\n",
    "                for i in xrange(buckets[-1][1] + 1): \n",
    "                        self.decoder_inputs.append(tf.placeholder(tf.int32, shape=[None], name=\"decoder{0}\".format(i)))\n",
    "                        self.target_weights.append(tf.placeholder(tf.float32, shape=[None], name=\"weight{0}\".format(i)))\n",
    "\n",
    "                # 타겟 심볼은 디코더 입력을 한 칸 shift 한 것과 같음\n",
    "                targets = [self.decoder_inputs[i + 1] for i in xrange(len(self.decoder_inputs) - 1)] \n",
    "                \n",
    "                # bucket을 사용한 seq2seq 사용\n",
    "                self.outputs, self.losses = tf.contrib.legacy_seq2seq.model_with_buckets(\n",
    "                                self.encoder_inputs, self.decoder_inputs, targets,\n",
    "                                self.target_weights, buckets,\n",
    "                                lambda x, y: seq2seq_f(x, y, False))\n",
    "                                \n",
    "                # 학습을 위한 그라디언트 계산\n",
    "                self.updates=[]\n",
    "                self.updates.append(tf.train.AdamOptimizer(learning_rate).minimize(self.losses[0]))\n",
    "\n",
    "        def step(self, session, encoder_inputs, decoder_inputs, target_weights, test):\n",
    "                bucket_id=0 # 학습 또는 추론할 bukcet 선택\n",
    "                encoder_size, decoder_size = self.buckets[bucket_id]\n",
    "\n",
    "                # Input feed: encoder inputs, decoder inputs, target_weights (placeholder에 값 넣기)\n",
    "                input_feed = {}\n",
    "                for l in xrange(encoder_size):\n",
    "                    input_feed[self.encoder_inputs[l].name] = [encoder_inputs[l]]\n",
    "                for l in xrange(decoder_size):\n",
    "                    input_feed[self.decoder_inputs[l].name] = [decoder_inputs[l]]\n",
    "                    input_feed[self.target_weights[l].name] = [target_weights[l]]\n",
    "\n",
    "                # 디코더 입력 노드가 한 개 추가 생성되었기 때문에 값을 넣어줌 (실제 사용되지는 않음).\n",
    "                last_target = self.decoder_inputs[decoder_size].name\n",
    "                input_feed[last_target] = np.zeros([self.batch_size], dtype=np.int32)\n",
    "                last_weight = self.target_weights[decoder_size].name\n",
    "                input_feed[last_weight] = np.zeros([self.batch_size], dtype=np.int32)\n",
    "\n",
    "                # Output feed: 테스트 할 때는 losses 값 출력, 훈련 할 때는 생성 글자와 losses 값 출력\n",
    "                if not test:\n",
    "                        output_feed = [self.updates[bucket_id], self.losses[bucket_id]]\n",
    "                else:\n",
    "                        output_feed = [self.losses[bucket_id]]  # Loss for this batch.\n",
    "                        for l in xrange(decoder_size):  # Output logits.\n",
    "                                output_feed.append(self.outputs[bucket_id][l])\n",
    "\n",
    "\n",
    "                outputs = session.run(output_feed, input_feed)\n",
    "                if not test:\n",
    "                        return outputs[0], outputs[1] # loss\n",
    "                else:\n",
    "                        return outputs[0], outputs[1:] # loss, outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode(bytes): # 아스키 코드를 텍스트로 변환\n",
    "    return \"\".join(map(chr, bytes)).replace('\\x00', '').replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    losses, outputs = model.step(session, input_data1, target_data, target_weights, test=True)\n",
    "    words = np.argmax(outputs, axis=2)  # shape (12, 12, 256)\n",
    "    word = decode(words)\n",
    "    print(\"step %d, losses %f, output: Hi Tacademy -> %s?\" % (step, losses, word))\n",
    "    if word == \"How are you\": # 성공적으로 문장을 생성하면 멈춤\n",
    "            print(\">>>>> success! Hi Tacademy -> \" + word + \"? <<<<<<<\")\n",
    "            import pdb\n",
    "            pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except NameError:\n",
    "    pass\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Korea\n",
      "step 30, losses 0.271949, output: Hi Korea -> How are you?\n",
      ">>>>> success! Hi Korea -> How are you? <<<<<<<\n",
      "--Return--\n",
      "> <ipython-input-11-d029d325f6d2>(9)<module>()->None\n",
      "-> pdb.set_trace()\n"
     ]
    }
   ],
   "source": [
    "print (input_string1)\n",
    "losses, outputs = model.step(session, input_data1, target_data, target_weights, test=True)\n",
    "words = np.argmax(outputs, axis=2)  # shape (12, 12, 256)\n",
    "word = decode(words)\n",
    "print(\"step %d, losses %f, output: Hi Korea -> %s?\" % (step, losses, word))\n",
    "if word == \"How are you\": # 성공적으로 문장을 생성하면 멈춤\n",
    "        print(\">>>>> success! Hi Korea -> \" + word + \"? <<<<<<<\")\n",
    "        import pdb\n",
    "        pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, losses 3.596446, output: Hi Tacademy ->          ?\n",
      "step 1, losses 2.999340, output: Hi Tacademy -> oooooooooooo?\n",
      "step 2, losses 7.391266, output: Hi Tacademy -> yyyyyyyyyyyy?\n",
      "step 3, losses 10.596905, output: Hi Tacademy -> HHHwwwwwwwww?\n",
      "step 4, losses 6.584672, output: Hi Tacademy -> H     r rrrr?\n",
      "step 5, losses 27.298582, output: Hi Tacademy -> o�����������?\n",
      "step 6, losses 6.741463, output: Hi Tacademy -> oooooooooooo?\n",
      "step 7, losses 4.503323, output: Hi Tacademy ->          ?\n",
      "step 8, losses 4.496377, output: Hi Tacademy ->             ?\n",
      "step 9, losses 3.890624, output: Hi Tacademy -> uuuuaaaaaaaa?\n",
      "step 10, losses 3.137373, output: Hi Tacademy -> rrrrrrrryaay?\n",
      "step 11, losses 3.203959, output: Hi Tacademy -> HHHHHHHHyyyy?\n",
      "step 12, losses 3.515731, output: Hi Tacademy -> oooooooooooo?\n",
      "step 13, losses 2.594977, output: Hi Tacademy -> oooowooooo?\n",
      "step 14, losses 2.304645, output: Hi Tacademy ->     yyu y?\n",
      "step 15, losses 2.063870, output: Hi Tacademy -> w   yyu y  ?\n",
      "step 16, losses 1.537099, output: Hi Tacademy -> H   yr  y  ?\n",
      "step 17, losses 1.991955, output: Hi Tacademy -> HHeeyeeeyeee?\n",
      "step 18, losses 1.508367, output: Hi Tacademy -> HHHoaa oa  e?\n",
      "step 19, losses 1.775647, output: Hi Tacademy -> Hoooaaooy�y?\n",
      "step 20, losses 1.556100, output: Hi Tacademy -> Hoooarooy�u?\n",
      "step 21, losses 1.033387, output: Hi Tacademy -> woo ar  y ?\n",
      "step 22, losses 1.224729, output: Hi Tacademy -> wow aa y?\n",
      "step 23, losses 0.851015, output: Hi Tacademy -> wow aau y ?\n",
      "step 24, losses 0.898337, output: Hi Tacademy -> Ho  arr a uu?\n",
      "step 25, losses 0.588619, output: Hi Tacademy -> Ho  are y uu?\n",
      "step 26, losses 0.602342, output: Hi Tacademy -> Howoyee y ?\n",
      "step 27, losses 0.496669, output: Hi Tacademy -> Howoaee yo?\n",
      "step 28, losses 0.440188, output: Hi Tacademy -> Howoare you?\n",
      "step 29, losses 0.431491, output: Hi Tacademy -> Ho  are you?\n",
      "step 30, losses 0.271949, output: Hi Tacademy -> How are you?\n",
      ">>>>> success! Hi Tacademy -> How are you? <<<<<<<\n",
      "--Return--\n",
      "> <ipython-input-6-88247ffd3380>(9)test()->None\n",
      "-> pdb.set_trace()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-23dd63759a8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# no outputs in training\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtest_step\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                 \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-88247ffd3380>\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\">>>>> success! Hi Tacademy -> \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mword\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"? <<<<<<<\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/lib/python2.7/bdb.pyc\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'return'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_return\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'exception'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/bdb.pyc\u001b[0m in \u001b[0;36mdispatch_return\u001b[1;34m(self, frame, arg)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe_returning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_return\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe_returning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/pdb.pyc\u001b[0m in \u001b[0;36muser_return\u001b[1;34m(self, frame, return_value)\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'__return__'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;33m>>\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'--Return--'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0muser_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/pdb.pyc\u001b[0m in \u001b[0;36minteraction\u001b[1;34m(self, frame, traceback)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_stack_entry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmdloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/cmd.pyc\u001b[0m in \u001b[0;36mcmdloop\u001b[1;34m(self, intro)\u001b[0m\n\u001b[0;32m    128\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_rawinput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                             \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m                         \u001b[1;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                             \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'EOF'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         )\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    679\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step=0\n",
    "test_step=1\n",
    "session = tf.Session(config=config)\n",
    "model= BabySeq2Seq(vocab_size, target_vocab_size, buckets, size=5, num_layers=1, batch_size=batch_size)\n",
    "session.run(tf.global_variables_initializer())\n",
    "while True:\n",
    "        model.step(session, input_data, target_data, target_weights, test=False) # no outputs in training\n",
    "        if step % test_step == 0:\n",
    "                test()\n",
    "        step=step+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

